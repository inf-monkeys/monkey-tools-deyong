from flask import Flask, request, jsonify, send_file
import requests
from flask_restx import Api, Resource, fields
import traceback
import logging
import base64
import os
import tempfile
import uuid
import shutil
from docx import Document
import openai
import io
import json
import asyncio
import aiohttp
import re
import time
import urllib.parse
from typing import List, Dict, Any
from lxml import etree
from werkzeug.utils import secure_filename
from datetime import datetime

# å¯¼å…¥è…¾è®¯äº‘OCR SDK
# æ³¨æ„ï¼šéœ€è¦å®‰è£… tencentcloud-sdk-python
try:
    from tencentcloud.common import credential
    from tencentcloud.common.profile.client_profile import ClientProfile
    from tencentcloud.common.profile.http_profile import HttpProfile
    from tencentcloud.ocr.v20181119 import ocr_client, models
except ImportError:
    print("è¯·å®‰è£…è…¾è®¯äº‘SDK: pip install tencentcloud-sdk-python")

app = Flask(__name__, static_folder=None)
api = Api(
    app,
    version="1.0",
    title="API Services",
    description="API Services including Document AI Translation and Dify QA",
)

# å¯¼å…¥æ–‡ä»¶æœåŠ¡æ‰€éœ€æ¨¡å—
from flask import send_file

# æ–‡ä»¶æ‰˜ç®¡ç›¸å…³é…ç½®
class Config:
    # æ–‡ä»¶æ‰˜ç®¡ç›®å½•
    OUTPUT_FILES_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'output_files')
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(OUTPUT_FILES_DIR, exist_ok=True)
    # æ–‡ä»¶è®¿é—®URLå‰ç¼€ï¼Œé»˜è®¤ä¸ºæœ¬åœ°å¼€å‘ç¯å¢ƒ
    FILE_ACCESS_URL_PREFIX = "http://localhost:5001/files/"
    # æ–‡ä»¶è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
    FILE_EXPIRY_SECONDS = 3600 * 24 * 7  # 7å¤©
    
# å°è¯•ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶åŠ è½½é…ç½®
try:
    if os.path.exists('config.py'):
        from config import Config as UserConfig
        Config.FILE_ACCESS_URL_PREFIX = getattr(UserConfig, 'FILE_ACCESS_URL_PREFIX', Config.FILE_ACCESS_URL_PREFIX)
        Config.FILE_EXPIRY_SECONDS = getattr(UserConfig, 'FILE_EXPIRY_SECONDS', Config.FILE_EXPIRY_SECONDS)
    elif os.environ.get('FILE_ACCESS_URL_PREFIX'):
        Config.FILE_ACCESS_URL_PREFIX = os.environ.get('FILE_ACCESS_URL_PREFIX')
    
    print(f"æ–‡ä»¶è®¿é—®URLå‰ç¼€: {Config.FILE_ACCESS_URL_PREFIX}")
except Exception as e:
    print(f"åŠ è½½é…ç½®å¤±è´¥: {str(e)}")

# è®¾ç½®å¼‚æ­¥ç¿»è¯‘çš„æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
MAX_CONCURRENT_REQUESTS = 10
# æ¯æ‰¹å¤„ç†çš„æ–‡æœ¬æ•°é‡
BATCH_SIZE = 20

# è®¾ç½®APIå¯†é’¥å’ŒURL
API_URL = "https://api.cursorai.art"
DIFY_API_URL = "https://api.dify.ai/v1"

# ç‰¹å®šè¯è¯­çš„å›ºå®šç¿»è¯‘
SPECIAL_TRANSLATIONS = {
    "ç­¾å": "KÃ½ tÃªn",
    "ç°½å": "KÃ½ tÃªn",  # ç¹ä½“
    "åºå·": "STT",
    "åºè™Ÿ": "STT",  # ç¹ä½“
    "ä¼šç­¾å•ä½": "ÄÆ¡n vá»‹ kÃ½ hiá»‡u",
    "æœƒç°½å–®ä½": "ÄÆ¡n vá»‹ kÃ½ hiá»‡u",  # ç¹ä½“
    "ç¼–åˆ¶": "ÄÆ°á»£c soáº¡n bá»Ÿi",
    "ç·¨åˆ¶": "ÄÆ°á»£c soáº¡n bá»Ÿi",  # ç¹ä½“
    "æè®®": "Äá» nghá»‹",
    "æè­°": "Äá» nghá»‹",  # ç¹ä½“
    "å®¡æ ¸": "XÃ©t duyá»‡t",
    "å¯©æ ¸": "XÃ©t duyá»‡t",  # ç¹ä½“
    "æ ¸å‡†": "PhÃª duyá»‡t",
    "å¾©æ ¸": "Duyá»‡t láº¡i",  # ç¹ä½“
    "å¤æ ¸": "Duyá»‡t láº¡i",
    "VND": "Ä‘",
    "æµç¨‹": "Quy trÃ¬nh",
    "æµç¨‹å›¾": "SÆ¡ Ä‘á»“ quy trÃ¬nh",
    "å‘å¥–": "PhÃ¡t thÆ°á»Ÿng",
    "æƒ…å½¢": "TÃ¬nh hÃ¬nh",
    "å¤„ç†": "Xá»­ lÃ½",
    "å¼€å•": "Má»Ÿ phiáº¿u",
    "è¯´æ˜": "Giáº£i thÃ­ch",
    "å—å¥–äºº": "NgÆ°á»i nháº­n thÆ°á»Ÿng",
    "ç­¾å­—": "KÃ½ tÃªn",
    "æ‰¹å‡†": "PhÃª duyá»‡t",
    "å…¬å‘Š": "ThÃ´ng bÃ¡o",
    "ç”Ÿæ•ˆ": "CÃ³ hiá»‡u lá»±c",
    "å­˜æ¡£": "LÆ°u trá»¯",
    "ç³»ç»Ÿ": "Há»‡ thá»‘ng",
    "æ¡£æ¡ˆ": "Há»“ sÆ¡",
    # æ•°å­—ç›¸å…³ç¿»è¯‘
    "ç™¾": "00",
    "ä½°": "00",  # ç¹ä½“
    "åƒ": "000",
    "ä»Ÿ": "000",  # ç¹ä½“
    "ä¸‡": "0000",
    "è¬": "0000",  # ç¹ä½“
    # æ·»åŠ è¡¨æ ¼ä¸­å¸¸è§çš„å•å…ƒæ ¼æ ‡é¢˜
    "å¥–åŠ±ç§ç±»": "Loáº¡i khen thÆ°á»Ÿng",
    "å¥–å‹°ç¨®é¡": "Loáº¡i khen thÆ°á»Ÿng",  # ç¹ä½“
    "ç»„ç»‡": "Tá»• chá»©c",
    "çµ„ç¹”": "Tá»• chá»©c",  # ç¹ä½“
    "éƒ¨é—¨": "Bá»™ pháº­n",
    "éƒ¨é–€": "Bá»™ pháº­n",  # ç¹ä½“
    "å…¬å¸": "CÃ´ng ty",
    "äººäº‹éƒ¨": "PhÃ²ng nhÃ¢n sá»±"
}

# åˆ›å»ºä¸Šä¼ æ–‡ä»¶çš„ç›®å½•
UPLOAD_FOLDER = 'uploads'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # é™åˆ¶ä¸Šä¼ æ–‡ä»¶å¤§å°ä¸º16MB
app.config['OUTPUT_FILES_DIR'] = Config.OUTPUT_FILES_DIR

ai_translation_ns = api.namespace("ai_translation", description="Document Translation API")
ocr_ns = api.namespace("ocr", description="è…¾è®¯äº‘OCR API")
dify_ns = api.namespace("dify", description="Dify API")
inference_ns = api.namespace("inference", description="Inference API")

# Define document translation request and response models
document_translation_request = ai_translation_ns.model(
    "DocumentTranslationRequest",
    {
        "url": fields.String(required=True, description="URL of the document to translate"),
        "target_language": fields.String(required=True, description="Target language for translation"),
        "special_requirements": fields.String(required=False, description="Special requirements for translation"),
        "api_key": fields.String(required=False, description="API key for translation service")
    }
)

document_translation_response = ai_translation_ns.model(
    "DocumentTranslationResponse",
    {
        "message": fields.String(description="Response message"),
        "document_url": fields.String(description="URL to the translated document"),
        "error": fields.String(description="Error message if any")
    }
)

class NoSuccessfulRequestLoggingFilter(logging.Filter):
    def filter(self, record):
        return "GET /" not in record.getMessage()

# è·å– Flask çš„é»˜è®¤æ—¥å¿—è®°å½•å™¨
log = logging.getLogger("werkzeug")
# åˆ›å»ºå¹¶æ·»åŠ è¿‡æ»¤å™¨
log.addFilter(NoSuccessfulRequestLoggingFilter())

@app.before_request
def before_request():
    request.app_id = request.headers.get("x-monkeys-appid")
    request.user_id = request.headers.get("x-monkeys-userid")
    request.team_id = request.headers.get("x-monkeys-teamid")
    request.workflow_id = request.headers.get("x-monkeys-workflowid")
    request.workflow_instance_id = request.headers.get("x-monkeys-workflow-instanceid")

# æ·»åŠ é™æ€æ–‡ä»¶æ‰˜ç®¡è·¯ç”±
@app.route('/files/<path:filename>')
def serve_file(filename):
    """æä¾›å¯¹æ–‡ä»¶çš„è®¿é—®"""
    return send_file(os.path.join(Config.OUTPUT_FILES_DIR, filename))

@api.errorhandler(Exception)
def handle_exception(error):
    return {"message": str(error)}, 500

@app.get("/manifest.json")
def get_manifest():
    return {
        "schema_version": "v1",
        "display_name": "Deyong",
        "namespace": "monkey_tools_deyong",
        "auth": {"type": "none"},
        "api": {"type": "openapi", "url": "/swagger.json"},
        "contact_email": "dev@inf-monkeys.com",
        "categories": ["ai", "translation", "document"],
        "description": {
            "zh-CN": "Deyong Tools",
            "en-US": "Deyong Tools"
        },
        "icon": "emoji:ğŸ“„:#3a8fe5",
        "credentials": [
            {
                "name": "cursor-ai",
                "type": "aksk",
                "displayName": {
                    "zh-CN": "Cursor AI",
                    "en-US": "Cursor AI"
                },
                "iconUrl": "emoji:ğŸ¤–:#3a8fe5",
                "properties": [
                    {
                        "displayName": {
                            "zh-CN": "ä» Cursor AI è·å–ä½ çš„ API Key",
                            "en-US": "Get your API Key from Cursor AI"
                        },
                        "type": "notice",
                        "name": "docs"
                    },
                    {
                        "displayName": {
                            "zh-CN": "API Key",
                            "en-US": "API Key"
                        },
                        "type": "string",
                        "name": "api_key",
                        "required": True
                    }
                ]
            },
            {
                "name": "dify",
                "type": "aksk",
                "displayName": {
                    "zh-CN": "Dify",
                    "en-US": "Dify"
                },
                "iconUrl": "https://dify.ai/favicon.ico",
                "properties": [
                    {
                        "displayName": {
                            "zh-CN": "ä» [Dify](https://dify.ai) è·å–ä½ çš„ API Key",
                            "en-US": "Get your API Key from [Dify](https://dify.ai)"
                        },
                        "type": "notice",
                        "name": "docs"
                    },
                    {
                        "displayName": {
                            "zh-CN": "API Key",
                            "en-US": "API Key"
                        },
                        "type": "string",
                        "name": "api_key",
                        "required": True
                    }
                ]
            }
        ]
    }

@app.route('/upload', methods=['POST'])
def upload_file():
    file_base64 = None
    file_type = None
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ä»æœ¬åœ°ä¸Šä¼ çš„æ–‡ä»¶
    if 'file' in request.files and request.files['file'].filename != '':
        file = request.files['file']
        
        # è·å–æ–‡ä»¶ç±»å‹
        file_type = file.filename.rsplit('.', 1)[1].lower() if '.' in file.filename else ''
        if file_type not in ['jpg', 'jpeg', 'png', 'bmp', 'pdf']:
            return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400
        
        # ä¿å­˜æ–‡ä»¶
        filename = secure_filename(file.filename)
        file_path = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(file_path)
        
        # å°†æ–‡ä»¶è½¬æ¢ä¸ºbase64ç¼–ç 
        with open(file_path, 'rb') as f:
            file_content = f.read()
            file_base64 = base64.b64encode(file_content).decode('utf-8')
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.remove(file_path)
        
    # æ£€æŸ¥æ˜¯å¦æä¾›äº†CDN URL
    elif 'cdn_url' in request.form and request.form['cdn_url'] != '':
        cdn_url = request.form['cdn_url']
        
        try:
            # ä»URLè·å–æ–‡ä»¶å†…å®¹
            response = requests.get(cdn_url, stream=True)
            response.raise_for_status() # ç¡®ä¿è¯·æ±‚æˆåŠŸ
            
            # ä»URLä¸­æå–æ–‡ä»¶ç±»å‹
            content_type = response.headers.get('Content-Type', '')
            if 'image/jpeg' in content_type:
                file_type = 'jpg'
            elif 'image/png' in content_type:
                file_type = 'png'
            elif 'image/bmp' in content_type:
                file_type = 'bmp'
            elif 'application/pdf' in content_type:
                file_type = 'pdf'
            else:
                # å°è¯•ä»URLä¸­è·å–æ–‡ä»¶æ‰©å±•å
                url_path = urllib.parse.urlparse(cdn_url).path
                file_type = url_path.rsplit('.', 1)[1].lower() if '.' in url_path else ''
            
            if file_type not in ['jpg', 'jpeg', 'png', 'bmp', 'pdf']:
                return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400
            
            # å°†æ–‡ä»¶å†…å®¹è½¬æ¢ä¸ºbase64
            file_content = response.content
            file_base64 = base64.b64encode(file_content).decode('utf-8')
            
        except requests.exceptions.RequestException as e:
            return jsonify({'error': f'æ— æ³•ä»CDNä¸‹è½½æ–‡ä»¶: {str(e)}'}), 400
    else:
        return jsonify({'error': 'æ²¡æœ‰æ–‡ä»¶è¢«ä¸Šä¼ æˆ–æä¾›CDN URL'}), 400
    
    return jsonify({
        'file_base64': file_base64,
        'file_type': file_type
    })

@ai_translation_ns.route("/document")
class DocumentTranslationResource(Resource):
    @ai_translation_ns.doc("translate_document")
    @ai_translation_ns.vendor(
        {
            "x-monkey-tool-name": "translate_document",
            "x-monkey-tool-categories": ["ai", "translation", "document"],
            "x-monkey-tool-display-name": {
                "zh-CN": "æ–‡æ¡£AIç¿»è¯‘",
                "en-US": "Document AI Translation",
            },
            "x-monkey-tool-description": {
                "zh-CN": "ä½¿ç”¨GPT-4oè¿›è¡Œæ–‡æ¡£ç¿»è¯‘",
                "en-US": "Document translation using GPT-4o",
            },
            "x-monkey-tool-icon": "emoji:ğŸ“„:#3a8fe5",
            "x-monkey-tool-input": [
                {
                    "displayName": {
                        "zh-CN": "Cursor AI APIå¯†é’¥",
                        "en-US": "Cursor AI API Key",
                    },
                    "name": "api_key",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "æ–‡æ¡£CDN URL",
                        "en-US": "Document CDN URL",
                    },
                    "name": "document_url",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "ç›®æ ‡è¯­è¨€",
                        "en-US": "Target Language",
                    },
                    "name": "target_language",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "ç‰¹æ®Šç¿»è¯‘è¦æ±‚",
                        "en-US": "Special Translation Requirements",
                    },
                    "name": "special_requirements",
                    "type": "string",
                    "required": False,
                }
            ],
            "x-monkey-tool-output": [
                {
                    "displayName": {
                        "zh-CN": "ç¿»è¯‘åçš„æ–‡æ¡£",
                        "en-US": "Translated Document",
                    },
                    "name": "translated_document",
                    "type": "file",
                }
            ],
            "x-monkey-tool-extra": {
                "estimateTime": 180,
            },
        }
    )
    @ai_translation_ns.expect(document_translation_request)
    @ai_translation_ns.response(200, "æˆåŠŸ", document_translation_response)
    @ai_translation_ns.response(400, "è¯·æ±‚æ— æ•ˆ", document_translation_response)
    @ai_translation_ns.response(401, "æœªæˆæƒ", document_translation_response)
    @ai_translation_ns.response(500, "æœåŠ¡å™¨é”™è¯¯", document_translation_response)
    def post(self):
        """
        Translate a Word document using GPT-4o
        
        This endpoint accepts a Word document from a CDN URL,
        translates it to the specified target language, and returns a bilingual document 
        with both the original text and the translation.
        
        Returns a Word document with the translated content.
        """
        try:
            # è·å–JSONè¯·æ±‚æ•°æ®
            json_data = request.json
            if not json_data:
                return {
                    "file_url": "",
                    "success": False,
                    "message": "æ— æ•ˆçš„è¯·æ±‚æ•°æ®ã€‚å¿…é¡»æä¾›æœ‰æ•ˆçš„JSONæ•°æ®ã€‚"
                }, 400
                
            api_key = json_data.get('api_key')
            if not api_key:
                return {
                    "file_url": "",
                    "success": False,
                    "message": "Missing API key"
                }, 401
                
            target_language = json_data.get('target_language')
            special_requirements = json_data.get('special_requirements', '')
            document_url = json_data.get('document_url')
            
            if not target_language:
                return {
                    "file_url": "",
                    "success": False,
                    "message": "Missing target language parameter"
                }, 400
                
            if not document_url:
                return {
                    "file_url": "",
                    "success": False,
                    "message": "æœªæä¾›æ–‡æ¡£CDN URL"
                }, 400
                
            # Create a temporary file to store the document
            temp_dir = tempfile.mkdtemp()
            input_file_path = os.path.join(temp_dir, f"input_{uuid.uuid4()}.docx")
            output_file_path = os.path.join(temp_dir, f"output_{uuid.uuid4()}.docx")
            
            # ä»URLä¸­æå–æ–‡ä»¶å
            url_path = urllib.parse.urlparse(document_url).path
            file_name = os.path.basename(url_path)
            if not file_name.endswith('.docx'):
                return {
                    "file_url": "",
                    "success": False,
                    "message": "åªæ”¯æŒ .docx æ ¼å¼çš„æ–‡ä»¶"
                }, 400
                
            try:
                # ä»URLä¸‹è½½æ–‡ä»¶
                response = requests.get(document_url, stream=True)
                response.raise_for_status()  # ç¡®ä¿è¯·æ±‚æˆåŠŸ
                
                # ä¿å­˜ä¸‹è½½çš„æ–‡ä»¶
                with open(input_file_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                        
            except requests.exceptions.RequestException as e:
                return {
                    "file_url": "",
                    "success": False,
                    "message": f"æ— æ³•ä»CDN URLä¸‹è½½æ–‡ä»¶: {str(e)}"
                }, 400
                
            # å¤„ç†æ–‡æ¡£
            translated_doc = self.translate_document(input_file_path, target_language, special_requirements, api_key)
            translated_doc.save(output_file_path)
            
            # åˆ é™¤è¾“å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œä½†ä¿ç•™è¾“å‡ºæ–‡ä»¶ä»¥ä¾›ä¸Šä¼ åˆ°S3
            os.remove(input_file_path)
            
            # åˆ›å»ºä¸€ä¸ªæŒä¹…åŒ–çš„è¾“å‡ºç›®å½•ï¼Œç¡®ä¿S3ä¸Šä¼ å·¥å…·èƒ½è®¿é—®åˆ°
            output_dir = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'output_files')
            os.makedirs(output_dir, exist_ok=True)
            
            # ç”Ÿæˆä¸€ä¸ªæœ‰æ„ä¹‰çš„æ–‡ä»¶åï¼ŒåŒ…å«æ—¶é—´æˆ³å’ŒåŸå§‹æ–‡ä»¶å
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            original_filename = os.path.basename(url_path)
            filename_base, _ = os.path.splitext(original_filename)
            persistent_filename = f"{filename_base}_{target_language}_{timestamp}.docx"
            persistent_filepath = os.path.join(output_dir, persistent_filename)
            
            # å¤åˆ¶ç¿»è¯‘åçš„æ–‡ä»¶åˆ°æŒä¹…åŒ–ç›®å½•
            shutil.copy2(output_file_path, persistent_filepath)
            
            # æ¸…ç†å‰©ä½™çš„ä¸´æ—¶æ–‡ä»¶
            os.remove(output_file_path)
            os.rmdir(temp_dir)
                
            # ç”Ÿæˆå¯è®¿é—®çš„URL
            file_url = f"{Config.FILE_ACCESS_URL_PREFIX}{persistent_filename}"
            
            # è¿”å›æ–‡ä»¶URLå’Œç›¸å…³ä¿¡æ¯
            return {
                "file_path": persistent_filepath,     # æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè·¯å¾„ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                "file_url": file_url,                # å¯è®¿é—®çš„URL
                "publicAccessUrl": file_url,         # ç»™S3ç”¨çš„å…¬å¼€è®¿é—®URL
                "filename": persistent_filename,      # æ–‡ä»¶å
                "success": True,
                "message": f"æ–‡æ¡£ç¿»è¯‘æˆåŠŸï¼Œå¯é€šè¿‡ {file_url} è®¿é—®"
            }
                
        except Exception as e:
            traceback.print_exc()
            return {
                "file_url": "",
                "success": False,
                "message": str(e)
            }, 500

    async def translate_text_async(self, text, session, target_language, special_requirements="", api_key=None):
        """
        ä½¿ç”¨ GPT-4o API å¼‚æ­¥ç¿»è¯‘ä¸­æ–‡æ–‡æœ¬
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            session: aiohttp å®¢æˆ·ç«¯ä¼šè¯
            target_language: ç›®æ ‡è¯­è¨€
            special_requirements: ç‰¹æ®Šç¿»è¯‘è¦æ±‚
        
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬
        """
        if not text.strip():
            return ""
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºå•ç‹¬çš„å­—ç¬¦æˆ–é˜¿æ‹‰ä¼¯æ•°å­—
        if len(text.strip()) <= 1 or text.strip().isdigit():
            return text
        
        # æ£€æŸ¥æ˜¯å¦ä¸ºç‰¹å®šè¯è¯­
        # if text.strip() in SPECIAL_TRANSLATIONS:
        #     return SPECIAL_TRANSLATIONS[text.strip()]
        
        try:
            # æ„å»º API è¯·æ±‚
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {api_key}"
            }
            
            # æ–°çš„OpenAI APIæ ¼å¼è¦æ±‚æœ‰userå‚æ•°
            data = {
                "model": "gpt-4o",
                "messages": [
                    {"role": "system", "content": f"ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡åˆ°{target_language}ç¿»è¯‘å™¨ã€‚è¯·å°†ç”¨æˆ·æä¾›çš„ä¸­æ–‡æ–‡æœ¬ç¿»è¯‘æˆ{target_language}ï¼Œåªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦æœ‰ä»»ä½•è§£é‡Šæˆ–é¢å¤–å†…å®¹ã€‚ä¿æŒåŸå§‹æ ¼å¼ï¼Œä½†ä¸è¦é‡å¤åŸæ–‡ä¸­çš„æ ‡ç‚¹ç¬¦å·ï¼Œç‰¹åˆ«æ˜¯åœ¨è¡Œå°¾çš„æ ‡ç‚¹ç¬¦å·ã€‚å¦‚æœåŸæ–‡ä¸­æœ‰æ ‡ç‚¹ç¬¦å·ï¼Œè¯·ä½¿ç”¨{target_language}ä¸­çš„å¯¹åº”æ ‡ç‚¹ç¬¦å·ï¼Œè€Œä¸æ˜¯é‡å¤ä½¿ç”¨åŸæ–‡çš„æ ‡ç‚¹ç¬¦å·ã€‚å¦‚æœé‡åˆ°å•ç‹¬çš„å­—æ¯æˆ–æ•°å­—ï¼Œè¯·ä¿æŒåŸæ ·ä¸ç¿»è¯‘ã€‚å¦‚æœæ–‡æœ¬ä¸­åŒ…å«â€œç™¾â€ã€â€œåƒâ€ã€â€œä¸‡â€ç­‰æ•°å­—å•ä½ï¼Œè¯·æŒ‰ç…§ç‰¹å®šè§„åˆ™ç¿»è¯‘ã€‚{special_requirements if special_requirements else ''}"},
                    {"role": "user", "content": text}
                ],
                "temperature": 0.3,
                "user": "translation_service"  # æ·»åŠ userå‚æ•°ä»¥æ»¡è¶³APIè¦æ±‚
            }
            
            # å‘é€ API è¯·æ±‚
            print(f"æ­£åœ¨å‘é€ç¿»è¯‘è¯·æ±‚: {text[:30]}...")
            async with session.post(f"{API_URL}/v1/chat/completions", headers=headers, json=data) as response:
                response_data = await response.json()
                
                # å¤„ç† API å“åº”
                if response.status == 200 and "choices" in response_data:
                    translated_text = response_data["choices"][0]["message"]["content"]
                    print(f"ç¿»è¯‘æˆåŠŸ: {translated_text[:30]}...")
                    return translated_text
                else:
                    print(f"ç¿»è¯‘å¤±è´¥: {response.status} - {response_data}")
                    return ""
        except Exception as e:
            print(f"ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            return ""

    async def batch_translate_texts(self, texts, target_language, special_requirements="", api_key=None):
        """
        æ‰¹é‡å¼‚æ­¥ç¿»è¯‘å¤šä¸ªæ–‡æœ¬
        
        Args:
            texts: è¦ç¿»è¯‘çš„æ–‡æœ¬åˆ—è¡¨
            target_language: ç›®æ ‡è¯­è¨€
            special_requirements: ç‰¹æ®Šç¿»è¯‘è¦æ±‚
        
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬åˆ—è¡¨
        """
        # åˆ›å»ºå¼‚æ­¥ä¼šè¯
        async with aiohttp.ClientSession() as session:
            # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘è¯·æ±‚æ•°
            semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)
            
            async def translate_with_semaphore(text):
                async with semaphore:
                    return await self.translate_text_async(text, session, target_language, special_requirements, api_key)
            
            # åˆ›å»ºæ‰€æœ‰ç¿»è¯‘ä»»åŠ¡
            tasks = [translate_with_semaphore(text) for text in texts]
            
            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
            results = await asyncio.gather(*tasks)
            return results
    
    def translate_text(self, text, target_language, special_requirements="", api_key=None):
        """
        åŒæ­¥ç‰ˆæœ¬çš„ç¿»è¯‘å‡½æ•°ï¼Œç”¨äºå…¼å®¹ç°æœ‰ä»£ç 
        
        Args:
            text: è¦ç¿»è¯‘çš„æ–‡æœ¬
            target_language: ç›®æ ‡è¯­è¨€
            special_requirements: ç‰¹æ®Šç¿»è¯‘è¦æ±‚
        
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬
        """
        if not text.strip():
            return ""
        
        # ä½¿ç”¨åŒæ­¥æ–¹å¼è°ƒç”¨å¼‚æ­¥å‡½æ•°
        try:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self.batch_translate_texts([text], target_language, special_requirements, api_key))[0]
            loop.close()
            return result
        except Exception as e:
            print(f"åŒæ­¥ç¿»è¯‘è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            return ""
    
    def process_docx(self, input_file_path, target_language, special_requirements, api_key=None):
        """
        å¤„ç†Wordæ–‡æ¡£ï¼Œç¿»è¯‘å…¶ä¸­çš„æ–‡æœ¬å¹¶åˆ›å»ºåŒè¯­æ–‡æ¡£
        
        Args:
            input_file_path: Wordæ–‡æ¡£è·¯å¾„
            target_language: ç›®æ ‡è¯­è¨€
            special_requirements: ç‰¹æ®Šç¿»è¯‘è¦æ±‚
            
        Returns:
            ç¿»è¯‘åçš„Documentå¯¹è±¡
        """
        # æ‰“å¼€åŸå§‹æ–‡æ¡£
        doc = Document(input_file_path)
        
        # ç¿»è¯‘æ­£æ–‡æ®µè½
        total_paragraphs = len(doc.paragraphs)
        print(f"æ–‡æ¡£å…±æœ‰ {total_paragraphs} ä¸ªæ®µè½")
        
        # æ”¶é›†éœ€è¦ç¿»è¯‘çš„æ®µè½æ–‡æœ¬
        paragraph_texts = []
        paragraph_refs = []
        
        for paragraph in doc.paragraphs:
            if paragraph.text.strip():
                paragraph_texts.append(paragraph.text)
                paragraph_refs.append(paragraph)
        
        # æ‰¹é‡å¹¶è¡Œç¿»è¯‘æ®µè½
        if paragraph_texts:
            print(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(paragraph_texts)} ä¸ªæ®µè½...")
            # ä½¿ç”¨å¼‚æ­¥æ–¹å¼æ‰¹é‡ç¿»è¯‘
            translated_texts = asyncio.run(self.batch_translate_texts(paragraph_texts, target_language, special_requirements, api_key))
            
            # åˆ›å»ºæ®µè½å’Œç¿»è¯‘ç»“æœçš„æ˜ å°„
            paragraphs_to_translate = []
            for paragraph, translated_text in zip(paragraph_refs, translated_texts):
                if translated_text.strip():
                    paragraphs_to_translate.append((paragraph, translated_text))
                else:
                    print(f"  è­¦å‘Š: æ®µè½ç¿»è¯‘å¤±è´¥ï¼Œä¸æ·»åŠ ç¿»è¯‘")
        else:
            paragraphs_to_translate = []
        
        # ç°åœ¨åœ¨åŸæ–‡åé¢æ·»åŠ ç¿»è¯‘æ–‡æœ¬
        # ä»åå¾€å‰éå†ï¼Œè¿™æ ·æˆ‘ä»¬åœ¨æ·»åŠ æ–°æ®µè½æ—¶ä¸ä¼šå½±å“å‰é¢çš„æ®µè½ç´¢å¼•
        for paragraph, translated_text in reversed(paragraphs_to_translate):
            try:
                # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹å¼æ’å…¥ç¿»è¯‘æ–‡æœ¬
                # ç›´æ¥åœ¨æ®µè½åé¢æ·»åŠ ä¸€ä¸ªæ–°æ®µè½
                p = doc.add_paragraph()
                # è·å–åŸæ®µè½çš„çˆ¶å…ƒç´ 
                parent_element = paragraph._p.getparent()
                # è·å–åŸæ®µè½åœ¨çˆ¶å…ƒç´ ä¸­çš„ç´¢å¼•
                if parent_element is not None:
                    index_in_parent = list(parent_element).index(paragraph._p)
                    # åœ¨åŸæ®µè½åé¢æ’å…¥æ–°æ®µè½
                    parent_element.insert(index_in_parent + 1, p._p)
            except Exception as e:
                print(f"  è­¦å‘Š: æ’å…¥æ®µè½æ—¶å‡ºé”™: {str(e)}")
                # å¦‚æœæ’å…¥å¤±è´¥ï¼Œå°è¯•ç›´æ¥åœ¨æ–‡æ¡£æœ«å°¾æ·»åŠ æ®µè½
                p = doc.add_paragraph()
            
            # è®¾ç½®ç¿»è¯‘æ–‡æœ¬å’Œæ ·å¼
            run = p.add_run(translated_text)
            
            # å¤åˆ¶åŸæ®µè½çš„æ ·å¼
            if paragraph.style:
                p.style = paragraph.style
            
            # å¤åˆ¶åŸæ®µè½çš„å¯¹é½æ–¹å¼
            if paragraph.alignment is not None:
                p.alignment = paragraph.alignment
            
            # å¦‚æœåŸæ®µè½æœ‰æ ¼å¼ï¼Œå¤åˆ¶å­—ä½“æ ¼å¼
            if paragraph.runs:
                # è·å–æ‰€æœ‰æ ¼å¼å±æ€§
                for orig_run in paragraph.runs:
                    if orig_run.font.size:
                        run.font.size = orig_run.font.size
                    if orig_run.font.name:
                        run.font.name = orig_run.font.name
                    # å¤åˆ¶åŠ ç²—ã€æ–œä½“ã€ä¸‹åˆ’çº¿ç­‰æ ¼å¼
                    if hasattr(orig_run.font, 'bold') and orig_run.font.bold:
                        run.font.bold = orig_run.font.bold
                    if hasattr(orig_run.font, 'italic') and orig_run.font.italic:
                        run.font.italic = orig_run.font.italic
                    if hasattr(orig_run.font, 'underline') and orig_run.font.underline:
                        run.font.underline = orig_run.font.underline
                    # å¤åˆ¶é¢œè‰²
                    if hasattr(orig_run.font, 'color') and orig_run.font.color and hasattr(orig_run.font.color, 'rgb') and orig_run.font.color.rgb:
                        run.font.color.rgb = orig_run.font.color.rgb
                    # ä¸€æ—¦æ‰¾åˆ°æœ‰æ ¼å¼çš„runï¼Œå°±ä½¿ç”¨å®ƒçš„æ ¼å¼
                    if any([orig_run.font.bold, orig_run.font.italic, orig_run.font.underline, orig_run.font.size]):
                        break
        
        # å¤„ç†è¡¨æ ¼
        all_table_cells = []
        all_table_texts = []
        
        # æ”¶é›†æ‰€æœ‰è¡¨æ ¼å•å…ƒæ ¼çš„æ–‡æœ¬
        for table in doc.tables:
            print("æ­£åœ¨å¤„ç†è¡¨æ ¼...")
            
            for row in table.rows:
                for cell in row.cells:
                    # è·å–å•å…ƒæ ¼çš„æ–‡æœ¬
                    cell_text = cell.text.strip()
                    
                    if cell_text:
                        all_table_cells.append(cell)
                        all_table_texts.append(cell_text)
        
        # æ‰¹é‡å¹¶è¡Œç¿»è¯‘è¡¨æ ¼å•å…ƒæ ¼
        if all_table_texts:
            print(f"å¼€å§‹æ‰¹é‡ç¿»è¯‘ {len(all_table_texts)} ä¸ªè¡¨æ ¼å•å…ƒæ ¼...")
            # ä½¿ç”¨å¼‚æ­¥æ–¹å¼æ‰¹é‡ç¿»è¯‘
            translated_table_texts = asyncio.run(self.batch_translate_texts(all_table_texts, target_language, special_requirements, api_key))
            
            # å¤„ç†ç¿»è¯‘ç»“æœ
            cell_translations = []
            for cell, translated_text in zip(all_table_cells, translated_table_texts):
                if translated_text.strip():
                    cell_translations.append((cell, translated_text))
                else:
                    print(f"  è­¦å‘Š: è¡¨æ ¼å•å…ƒæ ¼ç¿»è¯‘å¤±è´¥ï¼Œä¸æ·»åŠ ç¿»è¯‘")
            
            # åˆ›å»ºä¸€ä¸ªé›†åˆæ¥è·Ÿè¸ªå·²å¤„ç†çš„å•å…ƒæ ¼ï¼Œé˜²æ­¢é‡å¤å¤„ç†
            processed_cells = set()
            
            # å°†ç¿»è¯‘ç»“æœæ·»åŠ åˆ°è¡¨æ ¼å•å…ƒæ ¼ä¸­
            for cell, translated_text in zip(all_table_cells, translated_table_texts):
                # ä½¿ç”¨å•å…ƒæ ¼å¯¹è±¡çš„IDä½œä¸ºå”¯ä¸€æ ‡è¯†ç¬¦
                cell_id = id(cell)
                
                # å¦‚æœè¿™ä¸ªå•å…ƒæ ¼å·²ç»å¤„ç†è¿‡ï¼Œåˆ™è·³è¿‡
                if cell_id in processed_cells:
                    continue
                    
                # æ ‡è®°è¿™ä¸ªå•å…ƒæ ¼ä¸ºå·²å¤„ç†
                processed_cells.add(cell_id)
                
                try:
                    # æ£€æŸ¥å•å…ƒæ ¼æ˜¯å¦å·²ç»åŒ…å«ç¿»è¯‘
                    already_translated = False
                    
                    # è·å–æ‰€æœ‰æ®µè½æ–‡æœ¬ï¼Œæ£€æŸ¥æ˜¯å¦å·²åŒ…å«ç¿»è¯‘
                    all_cell_text = cell.text
                    if translated_text.strip() in all_cell_text:
                        print(f"  è·³è¿‡å·²ç¿»è¯‘çš„å•å…ƒæ ¼å†…å®¹")
                        continue
                    
                    # é€æ®µæ£€æŸ¥æ˜¯å¦å·²åŒ…å«ç¿»è¯‘
                    for para in cell.paragraphs[1:] if len(cell.paragraphs) > 1 else []:
                        if para.text.strip() == translated_text.strip():
                            already_translated = True
                            break
                            
                    if already_translated:
                        continue
                    
                    # æ·»åŠ ç¿»è¯‘æ®µè½
                    if len(cell.paragraphs) > 0 and cell.paragraphs[0].text.strip():
                        # æ·»åŠ æ–°æ®µè½
                        p = cell.add_paragraph()
                        p.text = translated_text
                        
                        # å°è¯•åº”ç”¨åŸå§‹æ®µè½çš„æ ·å¼
                        if cell.paragraphs[0].style:
                            p.style = cell.paragraphs[0].style
                except Exception as e:
                    print(f"  å¤„ç†è¡¨æ ¼å•å…ƒæ ¼æ—¶å‡ºé”™: {str(e)}")
        
        return doc
    
    def call_translation_api(self, input_file_path, target_language,api_key):
        """
        è°ƒç”¨app.pyä¸­çš„/api/translateæ¥å£æ¥ç¿»è¯‘æ–‡æ¡£
        
        Args:
            input_file_path: è¾“å…¥æ–‡æ¡£è·¯å¾„
            target_language: ç›®æ ‡è¯­è¨€
            
        Returns:
            ç¿»è¯‘åçš„æ–‡æ¡£è·¯å¾„
        """
        import requests
        import tempfile
        import os
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶æ¥ä¿å­˜ç¿»è¯‘åçš„æ–‡æ¡£
        temp_dir = tempfile.mkdtemp()
        output_path = os.path.join(temp_dir, f"translated_output.docx")
        
        # å‡†å¤‡APIè¯·æ±‚
        url = "http://localhost:5005/api/translate"  # app.pyè¿è¡Œçš„åœ°å€
        
        # å‡†å¤‡æ–‡ä»¶å’Œè¡¨å•æ•°æ®
        files = {
            'file': (os.path.basename(input_file_path), open(input_file_path, 'rb'), 'application/vnd.openxmlformats-officedocument.wordprocessingml.document')
        }
        data = {
            'target_language': target_language,
            'api_key': api_key
        }
        
        try:
            # å‘é€è¯·æ±‚
            print(f"æ­£åœ¨è°ƒç”¨ç¿»è¯‘API...")
            response = requests.post(url, files=files, data=data, stream=True)
            
            # æ£€æŸ¥å“åº”
            if response.status_code == 200:
                # å°†å“åº”å†…å®¹ä¿å­˜åˆ°æ–‡ä»¶
                with open(output_path, 'wb') as f:
                    for chunk in response.iter_content(chunk_size=8192):
                        f.write(chunk)
                print(f"ç¿»è¯‘æˆåŠŸï¼Œç»“æœä¿å­˜åˆ°: {output_path}")
                return output_path
            else:
                print(f"ç¿»è¯‘APIè°ƒç”¨å¤±è´¥: {response.status_code} - {response.text}")
                raise Exception(f"ç¿»è¯‘APIè°ƒç”¨å¤±è´¥: {response.status_code}")
        except Exception as e:
            print(f"è°ƒç”¨ç¿»è¯‘APIæ—¶å‡ºé”™: {str(e)}")
            raise e
        finally:
            # å…³é—­æ–‡ä»¶
            files['file'][1].close()
    
    def translate_document(self, input_file_path, target_language, special_requirements,api_key):
        """
        Translate a Word document using GPT-4o
        
        Args:
            input_file_path: Path to the input Word document
            target_language: Target language for translation
            special_requirements: Special translation requirements
            
        Returns:
            A Document object with the translated content
        """
        try:
            # è°ƒç”¨ç¿»è¯‘API
            output_path = self.call_translation_api(input_file_path, target_language,api_key)
            
            # è¿”å›ç¿»è¯‘åçš„æ–‡æ¡£
            return Document(output_path)
        except Exception as e:
            print(f"ç¿»è¯‘æ–‡æ¡£æ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœAPIè°ƒç”¨å¤±è´¥ï¼Œå›é€€åˆ°ä½¿ç”¨æœ¬åœ°ç¿»è¯‘æ–¹æ³•
            print("å°è¯•ä½¿ç”¨æœ¬åœ°ç¿»è¯‘æ–¹æ³•...")
            return self.process_docx(input_file_path, target_language, special_requirements, api_key)


# å®šä¹‰OCRè¯·æ±‚æ¨¡å‹
ocr_request = ocr_ns.model(
    "OCRRequest",
    {
        "image_url": fields.String(required=True, description="å›¾ç‰‡çš„URLåœ°å€"),
        "secret_id": fields.String(required=True, description="è…¾è®¯äº‘SecretId"),
        "secret_key": fields.String(required=True, description="è…¾è®¯äº‘SecretKey"),
    },
)

# å®šä¹‰å“åº”æ¨¡å‹
ocr_response = ocr_ns.model(
    "OCRResponse",
    {
        "extracted_text": fields.String(description="OCRæå–çš„åŸå§‹æ–‡æœ¬"),
        "success": fields.Boolean(description="OCRè¯†åˆ«æ˜¯å¦æˆåŠŸ"),
        "message": fields.String(description="å¤„ç†ç»“æœä¿¡æ¯")
    },
)

@ocr_ns.route("/extract")
class OCRExtractResource(Resource):
    @ocr_ns.doc("extract_text_from_document")
    @ocr_ns.vendor(
        {
            "x-monkey-tool-name": "extract_text_from_document",
            "x-monkey-tool-categories": ["ocr", "document-processing"],
            "x-monkey-tool-display-name": {
                "zh-CN": "ä»å›¾ç‰‡æå–æ–‡æœ¬",
                "en-US": "Extract Text from Image",
            },
            "x-monkey-tool-description": {
                "zh-CN": "ä½¿ç”¨è…¾è®¯äº‘OCRä»å›¾ç‰‡URLä¸­æå–æ–‡æœ¬",
                "en-US": "Extract text from image URL using Tencent Cloud OCR",
            },
            "x-monkey-tool-icon": "emoji:ğŸ“”:#4a90e2",
            "x-monkey-tool-input": [
                {
                    "displayName": {
                        "zh-CN": "å›¾ç‰‡URL",
                        "en-US": "Image URL",
                    },
                    "name": "image_url",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "è…¾è®¯äº‘SecretId",
                        "en-US": "Tencent Cloud SecretId",
                    },
                    "name": "secret_id",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "è…¾è®¯äº‘SecretKey",
                        "en-US": "Tencent Cloud SecretKey",
                    },
                    "name": "secret_key",
                    "type": "string",
                    "required": True,
                }
            ],
            "x-monkey-tool-output": [
                {
                    "displayName": {
                        "zh-CN": "æå–çš„æ–‡æœ¬",
                        "en-US": "Extracted Text",
                    },
                    "name": "extracted_text",
                    "type": "string",
                },
                {
                    "displayName": {
                        "zh-CN": "æ˜¯å¦æˆåŠŸ",
                        "en-US": "Success",
                    },
                    "name": "success",
                    "type": "boolean",
                },
                {
                    "displayName": {
                        "zh-CN": "ç»“æœä¿¡æ¯",
                        "en-US": "Message",
                    },
                    "name": "message",
                    "type": "string",
                }
            ],
            "x-monkey-tool-extra": {
                "estimateTime": 5,
            },
        }
    )
    @ocr_ns.expect(ocr_request)
    @ocr_ns.response(200, "æˆåŠŸ", ocr_response)
    def post(self):
        """
        ä½¿ç”¨è…¾è®¯äº‘OCRä»å›¾ç‰‡URLä¸­æå–æ–‡æœ¬
        """
        json_data = request.json
        image_url = json_data.get("image_url")
        secret_id = json_data.get("secret_id")
        secret_key = json_data.get("secret_key")
        
        # ä½¿ç”¨è…¾è®¯äº‘OCRæå–æ–‡æœ¬
        extracted_text = self.perform_ocr_from_url(image_url, secret_id, secret_key)
        
        if extracted_text.startswith("OCRé”™è¯¯"):
            return {
                "extracted_text": "",
                "success": False,
                "message": extracted_text
            }
        
        return {
            "extracted_text": extracted_text,
            "success": True,
            "message": "æ–‡æœ¬æå–æˆåŠŸ"
        }
    
    def perform_ocr_from_url(self, image_url, secret_id, secret_key):
        """ä½¿ç”¨è…¾è®¯äº‘OCR APIä»å›¾ç‰‡URLæå–æ–‡æœ¬"""
        try:
            # åˆ›å»ºè®¤è¯å¯¹è±¡
            cred = credential.Credential(secret_id, secret_key)
            
            # åˆ›å»ºå®¢æˆ·ç«¯é…ç½®
            httpProfile = HttpProfile()
            httpProfile.endpoint = "ocr.tencentcloudapi.com"  # APIç½‘å…³åœ°å€
            httpProfile.reqMethod = "POST"  # è¯·æ±‚æ–¹æ³•
            httpProfile.reqTimeout = 30    # è¶…æ—¶æ—¶é—´ï¼Œå•ä½ä¸ºç§’
            
            clientProfile = ClientProfile()
            clientProfile.httpProfile = httpProfile
            clientProfile.signMethod = "TC3-HMAC-SHA256"  # ç­¾åæ–¹æ³•
            
            # åˆ›å»ºOCRå®¢æˆ·ç«¯ï¼Œé»˜è®¤ä½¿ç”¨å¹¿å·åŒºåŸŸ
            client = ocr_client.OcrClient(cred, "ap-guangzhou", clientProfile)
            
            # åˆ›å»ºè¯·æ±‚å¯¹è±¡
            req = models.GeneralBasicOCRRequest()
            
            # è®¾ç½®å›¾ç‰‡URL
            req.ImageUrl = image_url
            
            # å¯é€‰å‚æ•°è®¾ç½®
            # req.LanguageType = "auto"  # è¯†åˆ«è¯­è¨€ç±»å‹ï¼Œé»˜è®¤ä¸ºè‡ªåŠ¨
            # req.Scene = "normal"       # åœºæ™¯å€¼ï¼Œé»˜è®¤ä¸ºé€šç”¨
            # req.IsWords = False        # æ˜¯å¦è¿”å›å•å­—ä¿¡æ¯
            
            # è°ƒç”¨é€šç”¨å°åˆ·ä½“è¯†åˆ«æ¥å£
            response = client.GeneralBasicOCR(req)
            
            # æå–æ–‡æœ¬å’Œä½ç½®ä¿¡æ¯
            result = []
            text_items = []
            for item in response.TextDetections:
                text_items.append(item.DetectedText)
                result.append({
                    "text": item.DetectedText,  # è¯†åˆ«å‡ºçš„æ–‡æœ¬
                    "confidence": item.Confidence,  # ç½®ä¿¡åº¦
                    "polygon": {  # æ–‡æœ¬æ¡†åæ ‡
                        "x": [item.Polygon[0].X, item.Polygon[1].X, item.Polygon[2].X, item.Polygon[3].X],
                        "y": [item.Polygon[0].Y, item.Polygon[1].Y, item.Polygon[2].Y, item.Polygon[3].Y]
                    } if hasattr(item, 'Polygon') and item.Polygon else None
                })
            
            # æ‰“å°è¯¦ç»†ç»“æœä¿¡æ¯ï¼ˆè°ƒè¯•ç”¨ï¼‰
            print(f"OCRè¯†åˆ«ç»“æœ: {response.to_json_string()}")
            
            # è¿”å›çº¯æ–‡æœ¬ç»“æœ
            return "\n".join(text_items)
        
        except Exception as e:
            print(f"OCRé”™è¯¯: {str(e)}")
            return f"OCRé”™è¯¯: {str(e)}"


# å®šä¹‰Dify QAè¯·æ±‚æ¨¡å‹
dify_request = dify_ns.model(
    "DifyRequest",
    {
        "api_key": fields.String(required=True, description="Dify APIå¯†é’¥"),
        "question": fields.String(required=True, description="è¦æé—®çš„é—®é¢˜"),
        "conversation_id": fields.String(required=False, description="å¯¹è¯IDï¼Œç”¨äºç»§ç»­ä¹‹å‰çš„å¯¹è¯"),
    },
)

# å®šä¹‰Dify QAå“åº”æ¨¡å‹
dify_response = dify_ns.model(
    "DifyResponse",
    {
        "answer": fields.String(description="AIå›ç­”çš„å†…å®¹"),
        "conversation_id": fields.String(description="å¯¹è¯ID"),
        "success": fields.Boolean(description="è¯·æ±‚æ˜¯å¦æˆåŠŸ")
    },
)

# å®šä¹‰æ–‡æ¡£ç¿»è¯‘è¯·æ±‚æ¨¡å‹
document_translation_request = ai_translation_ns.model(
    "DocumentTranslationRequest",
    {
        "document_url": fields.String(required=True, description="æ–‡æ¡£CDN URLï¼Œå¿…é¡»æ˜¯.docxæ ¼å¼æ–‡ä»¶"),
        "api_key": fields.String(required=True, description="Cursor AI APIå¯†é’¥"),
        "target_language": fields.String(required=True, description="ç›®æ ‡ç¿»è¯‘è¯­è¨€"),
        "special_requirements": fields.String(required=False, description="ç‰¹æ®Šç¿»è¯‘è¦æ±‚")
    },
)

# å®šä¹‰æ–‡æ¡£ç¿»è¯‘å“åº”æ¨¡å‹ï¼ˆè™½ç„¶å®é™…å“åº”æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼‰
document_translation_response = ai_translation_ns.model(
    "DocumentTranslationResponse",
    {
        "file_url": fields.String(description="ç¿»è¯‘åçš„æ–‡æ¡£URL"),
        "success": fields.Boolean(description="ç¿»è¯‘æ˜¯å¦æˆåŠŸ"),
        "message": fields.String(description="å¤„ç†ç»“æœä¿¡æ¯")
    },
)
@dify_ns.route("/qa")
class DifyQAResource(Resource):
    @dify_ns.doc("qa_service")
    @dify_ns.expect(dify_request)
    @dify_ns.response(200, "æˆåŠŸ", dify_response)
    @dify_ns.vendor(
        {
            "x-monkey-tool-name": "dify_qa",
            "x-monkey-tool-categories": ["ai", "qa"],
            "x-monkey-tool-display-name": {
                "zh-CN": "Difyé—®ç­”æœåŠ¡",
                "en-US": "Dify QA Service",
            },
            "x-monkey-tool-description": {
                "zh-CN": "ä½¿ç”¨Dify APIè¿›è¡Œé—®ç­”",
                "en-US": "Use Dify API for QA",
            },
            "x-monkey-tool-icon": "emoji:ğŸ“„:#3a8fe5",
            "x-monkey-tool-input": [
                {
                    "displayName": {
                        "zh-CN": "Dify APIå¯†é’¥",
                        "en-US": "Dify API Key",
                    },
                    "name": "api_key",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "é—®é¢˜",
                        "en-US": "Question",
                    },
                    "name": "question",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "å¯¹è¯ID",
                        "en-US": "Conversation ID",
                    },
                    "name": "conversation_id",
                    "type": "string",
                    "required": False,
                }
            ],
            "x-monkey-tool-output": [
                {
                    "displayName": {
                        "zh-CN": "å›ç­”",
                        "en-US": "Answer",
                    },
                    "name": "answer",
                    "type": "string",
                },
                {
                    "displayName": {
                        "zh-CN": "å¯¹è¯ID",
                        "en-US": "Conversation ID",
                    },
                    "name": "conversation_id",
                    "type": "string",
                },
                {
                    "displayName": {
                        "zh-CN": "æˆåŠŸ",
                        "en-US": "Success",
                    },
                    "name": "success",
                    "type": "boolean",
                }
            ],
            "x-monkey-tool-extra": {
                "estimateTime": 5,
            },
        }
    )
    def post(self):
        
            # è·å–è¯·æ±‚æ•°æ®
            data = request.json
            api_key = data.get("api_key")
            if not api_key:
                return {"error": "Missing Dify API key"}, 401
                
            question = data.get("question")
            conversation_id = data.get("conversation_id", "")


            if not question:
                return {"error": "é—®é¢˜ä¸èƒ½ä¸ºç©º"}, 400
            
            # å‡†å¤‡è¯·æ±‚å¤´
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            }
            user_id = "user-" + str(hash(datetime.now().strftime('%Y%m%d%H%M%S')))
            # å‡†å¤‡è¯·æ±‚æ•°æ®
            data = {
                "inputs": {},
                "query": question,
                "user": user_id,
                "response_mode": "blocking",
            }

            # ä»…å½“ä¼šè¯IDå­˜åœ¨ä¸”æœ‰æ•ˆæ—¶æ‰æ·»åŠ åˆ°è¯·æ±‚ä¸­
            import re
            uuid_pattern = re.compile(r'^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$', re.I)
            if conversation_id and (isinstance(conversation_id, str) and uuid_pattern.match(conversation_id)):
                data["conversation_id"] = conversation_id
            
            try:
                # å‘é€è¯·æ±‚åˆ°Dify API
                response = requests.post(
                    f"{DIFY_API_URL}/chat-messages",
                    headers=headers,
                    json=data
                )
                
                if response.status_code == 200:
                    result = response.json()
                    answer = result.get("answer", "æŠ±æ­‰ï¼Œæˆ‘æ— æ³•å›ç­”è¿™ä¸ªé—®é¢˜ã€‚")
                    
                    # è¿”å›ç»“æœ
                    return {
                        "answer": answer,
                        "conversation_id": result.get("conversation_id", ""),
                        "success": True
                    }
                else:
                    return {"error": f"APIè¯·æ±‚å¤±è´¥: {response.text}"}, response.status_code
            
            except Exception as e:
                error_msg = f"å‘ç”Ÿé”™è¯¯: {str(e)}"
                return {"answer": error_msg, "success": False}


def extract_formulas_from_response(response_text: str) -> List[str]:
    """
    ä» GPT-o3 API çš„å“åº”æ–‡æœ¬ä¸­æå–æ•°å­¦å…¬å¼
    
    Args:
        response_text: GPT-o3 è¿”å›çš„æ–‡æœ¬å“åº”
        
    Returns:
        æå–å‡ºçš„å…¬å¼åˆ—è¡¨
    """
    formulas = []
    
    # å°è¯•æŸ¥æ‰¾å¸¸è§çš„å…¬å¼æ ‡è®°
    formula_markers = [
        "å…¬å¼ï¼š", "å…¬å¼:", "å…¬å¼æ˜¯", "å…¬å¼ä¸º", "è¡¨è¾¾å¼ï¼š", "è¡¨è¾¾å¼:", 
        "æ•°å­¦å…¬å¼ï¼š", "æ•°å­¦å…¬å¼:", "formula:", "formulaï¼š", "equation:", "equationï¼š",
        "f(x) =", "f(n) =", "y =", "Y =", "output =", "a_n ="
    ]
    
    # åˆ†å‰²æ–‡æœ¬ä¸ºè¡Œ
    lines = response_text.split('\n')
    
    # éå†æ¯ä¸€è¡ŒæŸ¥æ‰¾å…¬å¼
    for line in lines:
        line = line.strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not line:
            continue
            
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å…¬å¼æ ‡è®°
        for marker in formula_markers:
            if marker in line:
                # æå–å…¬å¼éƒ¨åˆ†
                formula_part = line[line.find(marker):].strip()
                if formula_part and len(formula_part) > len(marker):
                    formulas.append(formula_part)
                    break
        
        # æ£€æŸ¥æ˜¯å¦æœ‰ Markdown ä»£ç å—ä¸­çš„å…¬å¼
        if line.startswith('```') and ('math' in line or 'latex' in line):
            # æŸ¥æ‰¾ä»£ç å—ç»“æŸ
            in_code_block = True
            code_block_content = []
            for next_line in lines[lines.index(line) + 1:]:  
                if next_line.strip() == '```':
                    in_code_block = False
                    break
                code_block_content.append(next_line.strip())
            
            if code_block_content and not in_code_block:
                formulas.append(''.join(code_block_content))
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ˜ç¡®çš„å…¬å¼æ ‡è®°ï¼Œå°è¯•æŸ¥æ‰¾å¯èƒ½çš„å…¬å¼æ¨¡å¼
    if not formulas:
        # æŸ¥æ‰¾åŒ…å«ç­‰å·å’Œæ•°å­¦ç¬¦å·çš„è¡Œ
        math_symbols = ['+', '-', '*', '/', '^', '=', '(', ')', '[', ']', '{', '}', '\\', 'sqrt', 'log', 'sin', 'cos']
        for line in lines:
            line = line.strip()
            if '=' in line and any(sym in line for sym in math_symbols):
                formulas.append(line)
    
    # å»é‡å¹¶è¿”å›
    return list(set(formulas))


def analyze_data_patterns(data_points: List[float]) -> Dict[str, Any]:
    """
    åˆ†ææ•°æ®ç‚¹ä¹‹é—´çš„è§„å¾‹å’Œå…³ç³»
    """
    results = {}
    
    # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯
    results["count"] = len(data_points)
    results["min"] = min(data_points)
    results["max"] = max(data_points)
    results["mean"] = np.mean(data_points)
    results["median"] = np.median(data_points)
    
    # æ£€æŸ¥ç­‰å·®æ•°åˆ—
    differences = [data_points[i+1] - data_points[i] for i in range(len(data_points)-1)]
    if len(set(round(diff, 6) for diff in differences)) == 1:
        results["arithmetic_sequence"] = True
        results["common_difference"] = differences[0]
        results["formula"] = f"a_n = {data_points[0]} + (n-1) * {differences[0]}"
    else:
        results["arithmetic_sequence"] = False
    
    # æ£€æŸ¥ç­‰æ¯”æ•°åˆ—
    if all(x > 0 for x in data_points):
        ratios = [data_points[i+1] / data_points[i] for i in range(len(data_points)-1)]
        if len(set(round(ratio, 6) for ratio in ratios)) == 1:
            results["geometric_sequence"] = True
            results["common_ratio"] = ratios[0]
            results["formula"] = f"a_n = {data_points[0]} * ({ratios[0]})^(n-1)"
        else:
            results["geometric_sequence"] = False
    else:
        results["geometric_sequence"] = False
    
    # æ£€æŸ¥äºŒæ¬¡å‡½æ•°å…³ç³»
    if len(data_points) >= 3:
        x = np.array(range(1, len(data_points) + 1))
        y = np.array(data_points)
        
        # çº¿æ€§æ‹Ÿåˆ
        linear_coeffs = np.polyfit(x, y, 1)
        linear_y_pred = np.polyval(linear_coeffs, x)
        linear_residuals = y - linear_y_pred
        linear_mse = np.mean(linear_residuals ** 2)
        
        # äºŒæ¬¡æ‹Ÿåˆ
        quad_coeffs = np.polyfit(x, y, 2)
        quad_y_pred = np.polyval(quad_coeffs, x)
        quad_residuals = y - quad_y_pred
        quad_mse = np.mean(quad_residuals ** 2)
        
        # æ‰¾å‡ºæœ€ä½³æ‹Ÿåˆ
        if linear_mse < 1e-6:
            results["best_fit"] = "linear"
            results["formula"] = f"f(n) = {linear_coeffs[0]:.6f}*n + {linear_coeffs[1]:.6f}"
            results["coefficients"] = linear_coeffs.tolist()
        elif quad_mse < 1e-6:
            results["best_fit"] = "quadratic"
            results["formula"] = f"f(n) = {quad_coeffs[0]:.6f}*n^2 + {quad_coeffs[1]:.6f}*n + {quad_coeffs[2]:.6f}"
            results["coefficients"] = quad_coeffs.tolist()
    
    return results

def call_gpt_o3(json_data, api_key) -> Dict[str, Any]:
    """
    è°ƒç”¨ GPT-o3 API æ¥è¿›è¡Œæ•°æ®æ¨ç†
    """
    try:
        # æ„å»º API è¯·æ±‚
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }
        
        # æ„å»ºç¤ºä¾‹æ•°æ®
        # example_data = {
        #   "data": [
        #     {
        #       "instruction": "X1X2X3:193.0,22.0,88.0",
        #       "input": "",
        #       "output": "Y1Y2Y3:42.18,65.42,8.9"
        #     },
        #     {
        #       "instruction": "X1X2X3:243.0,175.0,76.0",
        #       "input": "",
        #       "output": "Y1Y2Y3:76.22,15.6,58.75"
        #     }
        #   ]
        # }
        example_data = {
          "data": [
            {
              
            }
          ]
        }
        
        
        # æ„å»ºGPT-o3çš„æç¤ºè¯
        prompt = """ä»¥ä¸‹æ˜¯JSONæ ¼å¼çš„æ•°æ®ï¼Œinstructionå’Œoutputä¹‹é—´å­˜åœ¨å…³è”ã€‚è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
1. åˆ†æinstructionå’Œoutputä¹‹é—´çš„æ•°å­¦å…³ç³»
2. ç»™å‡ºèƒ½å¤Ÿä»instructionæ¨å¯¼å‡ºoutputçš„ç²¾ç¡®å…¬å¼
3. åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„Pythonä»£ç æ–‡ä»¶ï¼Œè¯¥æ–‡ä»¶åº”åŒ…å«ï¼š
   - ä¸€ä¸ªå‡½æ•°ï¼Œèƒ½å¤Ÿæ¥æ”¶instructionæ ¼å¼çš„è¾“å…¥å¹¶è¿”å›å¯¹åº”çš„output
   - æ¸…æ™°çš„æ³¨é‡Šï¼Œè§£é‡Šæ•°æ®ä¹‹é—´çš„å…³ç³»å’Œè½¬æ¢é€»è¾‘
   - ç¤ºä¾‹ä»£ç ï¼Œå±•ç¤ºå¦‚ä½•ä½¿ç”¨è¯¥å‡½æ•°å¤„ç†ç¤ºä¾‹æ•°æ®
   - å¿…è¦çš„è¾…åŠ©å‡½æ•°å’Œæ•°æ®å¤„ç†é€»è¾‘

è¯·ç¡®ä¿Pythonä»£ç æ˜¯å®Œæ•´çš„ã€å¯æ‰§è¡Œçš„ï¼Œå¹¶èƒ½å‡†ç¡®è¡¨è¾¾æ•°æ®ä¹‹é—´çš„å…³ç³»ã€‚
    """
        
        # å¦‚æœç”¨æˆ·æä¾›äº†è‡ªå®šä¹‰æ•°æ®ï¼Œä½¿ç”¨ç”¨æˆ·æ•°æ®ï¼Œå¦åˆ™ä½¿ç”¨ç¤ºä¾‹æ•°æ®
        data_to_analyze = json_data if json_data else example_data
        # data_to_analyze = example_data
        user_message = f"{prompt}\n\n{json.dumps(data_to_analyze, ensure_ascii=False, indent=2)}"
        
        messages = [
            {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªæ•°æ®åˆ†æä¸“å®¶ï¼Œæ“…é•¿å‘ç°æ•°æ®ä¹‹é—´çš„è§„å¾‹å’Œå…¬å¼ã€‚"},
            {"role": "user", "content": user_message}
        ]
        
        data = {
            "model": "gpt-4o",  # æŒ‡å®šä½¿ç”¨ GPT-o3 æ¨¡å‹ ï¼Œç›®å‰ç”¨apiè·‘o3æœ‰ç‚¹é—®é¢˜ï¼Œå…ˆæš‚æ—¶ç”¨4o
            "messages": messages,
            "temperature": 0.3  # è®¾ç½®æ¸©åº¦
        }
        
        # å‘é€ API è¯·æ±‚
        print(f"æ­£åœ¨å‘é€æ•°æ®åˆ†æè¯·æ±‚...")
        response = requests.post(f"{API_URL}/v1/chat/completions", headers=headers, json=data, timeout=30)
        
        # å¤„ç† API å“åº”
        if response.status_code == 200 and "choices" in response.json():
            gpt_response = response.json()
            ai_message = gpt_response["choices"][0]["message"]["content"]
            print(f"åˆ†ææˆåŠŸ!")
            
            # ä»å“åº”ä¸­æå–Pythonä»£ç 
            python_code = ""
            # æŸ¥æ‰¾Pythonä»£ç å—
            code_blocks = re.findall(r'```python\n([\s\S]*?)```', ai_message)
            if code_blocks:
                python_code = code_blocks[0]
            
            # è¿”å›ç»“æœ
            return {
                "input_data": json_data,
                "analysis_time": time.time(),
                "prompt_used": prompt,
                "analysis_result": ai_message,
                "python_code": python_code
            }
        else:
            # API è°ƒç”¨å¤±è´¥
            error_msg = f"åˆ†æå¤±è´¥: {response.status_code} - {response.text}"
            print(error_msg)
            return {
                "input_data": json_data,
                "error": error_msg
            }
    except Exception as e:
        # å¼‚å¸¸å¤„ç†
        error_msg = f"API è°ƒç”¨å¼‚å¸¸: {str(e)}"
        print(error_msg)
        traceback.print_exc()
        return {
            "input_data": json_data,
            "error": error_msg
        }


@inference_ns.route("/o3")
class InferenceO3Resource(Resource):
    @inference_ns.doc("infer_data_patterns")
    @inference_ns.vendor(
        {
            "x-monkey-tool-name": "infer_data_patterns",
            "x-monkey-tool-categories": ["data_analysis", "inference"],
            "x-monkey-tool-display-name": {
                "zh-CN": "æ•°æ®è§„å¾‹æ¨ç†",
                "en-US": "Data Pattern Inference",
            },
            "x-monkey-tool-description": {
                "zh-CN": "åˆ†ææ•°æ®ä¹‹é—´çš„è§„å¾‹å’Œå¯æ¢ç®—çš„å…¬å¼",
                "en-US": "Analyze patterns and formulas between data points",
            },
            "x-monkey-tool-icon": "emoji:ğŸ“Š:#4a90e2",
            "x-monkey-tool-input": [
                {
                    "displayName": {
                        "zh-CN": "Cursor AI APIå¯†é’¥",
                        "en-US": "Cursor AI API Key",
                    },
                    "name": "api_key",
                    "type": "string",
                    "required": True,
                },
                {
                    "displayName": {
                        "zh-CN": "æ•°æ®ç‚¹",
                        "en-US": "Data Points",
                    },
                    "name": "data_points",
                    "type": "array",
                    "required": True,
                    "description": {
                        "zh-CN": "è¦åˆ†æçš„æ•°æ®ç‚¹åˆ—è¡¨",
                        "en-US": "List of data points to analyze",
                    }
                },
                {
                    "displayName": {
                        "zh-CN": "åˆ†ææ¨¡å¼",
                        "en-US": "Analysis Mode",
                    },
                    "name": "analysis_mode",
                    "type": "string",
                    "required": False,
                    "description": {
                        "zh-CN": "åˆ†ææ¨¡å¼ï¼Œæ”¯æŒ 'basic' å’Œ 'advanced'",
                        "en-US": "Analysis mode, supports 'basic' and 'advanced'",
                    }
                }
            ],
            "x-monkey-tool-output": [
                {
                    "displayName": {
                        "zh-CN": "æ•°æ®ç‚¹",
                        "en-US": "Data Points",
                    },
                    "name": "data_points",
                    "type": "array",
                },
                {
                    "displayName": {
                        "zh-CN": "åˆ†ææ—¶é—´",
                        "en-US": "Analysis Time",
                    },
                    "name": "analysis_time",
                    "type": "number",
                },
                {
                    "displayName": {
                        "zh-CN": "ä½¿ç”¨çš„æç¤ºè¯",
                        "en-US": "Prompt Used",
                    },
                    "name": "prompt_used",
                    "type": "string",
                },
                {
                    "displayName": {
                        "zh-CN": "åŸºæœ¬è§„å¾‹",
                        "en-US": "Basic Patterns",
                    },
                    "name": "basic_patterns",
                    "type": "object",
                },
                {
                    "displayName": {
                        "zh-CN": "é«˜çº§æ´å¯Ÿ",
                        "en-US": "Advanced Insights",
                    },
                    "name": "advanced_insights",
                    "type": "object",
                }
            ],
            "x-monkey-tool-extra": {
                "estimateTime": 10,
                "provider": "GPT-o3",
            },
            "x-monkey-tool-credentials": [
                {
                    "name": "cursor-ai",
                    "required": True,
                    "description": {
                        "zh-CN": "Cursor AI API å¯†é’¥",
                        "en-US": "Cursor AI API Key"
                    }
                }
            ]
        }
    )
    @inference_ns.expect(
        inference_ns.model(
            "DataInferenceRequest",
            {
                "api_key": fields.String(required=True, description="Cursor AI APIå¯†é’¥"),
                "data": fields.Raw(description="Any valid JSON data, including arrays and objects")
            }
        )
    )
    @inference_ns.response(
        200,
        "Success",
        inference_ns.model(
            "DataInferenceResult",
            {
                "input_data": fields.Raw(description="The input JSON data"),
                "analysis_time": fields.Float(description="Analysis timestamp"),
                "prompt_used": fields.String(description="The prompt used for GPT-o3 analysis"),
                "analysis_result": fields.String(description="Analysis result from GPT-o3"),
                "python_code": fields.String(description="Extracted Python code that represents the data relationship")
            },
        ),
    )
    def post(self):
        """
        åˆ†ææ•°æ®ç‚¹ä¹‹é—´çš„è§„å¾‹å’Œå¯æ¢ç®—çš„å…¬å¼
        """
        try:
            # è·å–è¯·æ±‚æ•°æ®
            request_data = request.json
            if request_data is None:
                return {"message": "Invalid request data. Must provide valid JSON data."}, 400
            
            # è·å–APIå¯†é’¥
            api_key = request_data.get('api_key')
            if not api_key:
                return {"error": "Missing API key"}, 401
                
            # å¦‚æœè¯·æ±‚ä¸­æœ‰ data å­—æ®µï¼Œåˆ™ä½¿ç”¨è¯¥å­—æ®µçš„å€¼
            # å¦åˆ™ç›´æ¥ä½¿ç”¨æ•´ä¸ªè¯·æ±‚æ•°æ®
            json_data = request_data.get('data', request_data)
            
            # ç›´æ¥å°† JSON æ•°æ®å‘é€ç»™ GPT-o3 è¿›è¡Œåˆ†æ
            result = call_gpt_o3(json_data, api_key)
            
            return result
            
        except Exception as e:
            # å¼‚å¸¸å¤„ç†
            traceback.print_exc()
            return {"message": f"Error analyzing data: {str(e)}"}, 500


if __name__ == "__main__":
    app.run(host="0.0.0.0", port=5001)
